version: '3'

services:
  airflow-worker:
    image: ${AIRFLOW_IMAGE_NAME:-lcaf_v2}
    command: celery worker -q 106_worker
    hostname: ${HOSTNAME}
    ports:
      - 8793:8793
    healthcheck:
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 10s
      timeout: 10s
      retries: 5
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@10.120.4.109/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@10.120.4.109/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://:@10.120.4.109:6379/0
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT: 8793
      AIRFLOW__WEBSERVER__SECRET_KEY: b'\x92V\x13\xf6s\xe2\x88\xc7J\xd5\xee\x11\x17]C]'
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
      AIRFLOW__CORE__EXECUTE_TASKS_NEW_PYTHON_INTERPRETER: 'True'
      NUMEXPR_MAX_THREADS: 64
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
      AIRFLOW__EXECUTOR: CeleryExecutor

    volumes:
    # - ./dags:/opt/airflow/dags
      - /data/airflow/logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
      - test_volume:/opt/airflow/test_volume
      - /data/infrastructure/pipeline:/opt/airflow/dags
      - /home/lotte/.ssh:/home/airflow/.ssh

    restart: always
    privileged: true

volumes:
  test_volume:

# networks:
#   default:
#     external: 
#       name: test_network
